{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GR 5073 Midterm\n",
    "## Yi YIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. \n",
    "Import the spam dataset and print the first six rows.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make:</th>\n",
       "      <th>word_freq_address:</th>\n",
       "      <th>word_freq_all:</th>\n",
       "      <th>word_freq_3d:</th>\n",
       "      <th>word_freq_our:</th>\n",
       "      <th>word_freq_over:</th>\n",
       "      <th>word_freq_remove:</th>\n",
       "      <th>word_freq_internet:</th>\n",
       "      <th>word_freq_order:</th>\n",
       "      <th>word_freq_mail:</th>\n",
       "      <th>...</th>\n",
       "      <th>char_freq_;:</th>\n",
       "      <th>char_freq_(:</th>\n",
       "      <th>char_freq_[:</th>\n",
       "      <th>char_freq_!:</th>\n",
       "      <th>char_freq_$:</th>\n",
       "      <th>char_freq_#:</th>\n",
       "      <th>capital_run_length_average:</th>\n",
       "      <th>capital_run_length_longest:</th>\n",
       "      <th>capital_run_length_total:</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61</td>\n",
       "      <td>278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>15</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_freq_make:  word_freq_address:  word_freq_all:  word_freq_3d:  \\\n",
       "0             0.00                0.64            0.64            0.0   \n",
       "1             0.21                0.28            0.50            0.0   \n",
       "2             0.06                0.00            0.71            0.0   \n",
       "3             0.00                0.00            0.00            0.0   \n",
       "4             0.00                0.00            0.00            0.0   \n",
       "5             0.00                0.00            0.00            0.0   \n",
       "\n",
       "   word_freq_our:  word_freq_over:  word_freq_remove:  word_freq_internet:  \\\n",
       "0            0.32             0.00               0.00                 0.00   \n",
       "1            0.14             0.28               0.21                 0.07   \n",
       "2            1.23             0.19               0.19                 0.12   \n",
       "3            0.63             0.00               0.31                 0.63   \n",
       "4            0.63             0.00               0.31                 0.63   \n",
       "5            1.85             0.00               0.00                 1.85   \n",
       "\n",
       "   word_freq_order:  word_freq_mail:  ...   char_freq_;:  char_freq_(:  \\\n",
       "0              0.00             0.00  ...           0.00         0.000   \n",
       "1              0.00             0.94  ...           0.00         0.132   \n",
       "2              0.64             0.25  ...           0.01         0.143   \n",
       "3              0.31             0.63  ...           0.00         0.137   \n",
       "4              0.31             0.63  ...           0.00         0.135   \n",
       "5              0.00             0.00  ...           0.00         0.223   \n",
       "\n",
       "   char_freq_[:  char_freq_!:  char_freq_$:  char_freq_#:  \\\n",
       "0           0.0         0.778         0.000         0.000   \n",
       "1           0.0         0.372         0.180         0.048   \n",
       "2           0.0         0.276         0.184         0.010   \n",
       "3           0.0         0.137         0.000         0.000   \n",
       "4           0.0         0.135         0.000         0.000   \n",
       "5           0.0         0.000         0.000         0.000   \n",
       "\n",
       "   capital_run_length_average:  capital_run_length_longest:  \\\n",
       "0                        3.756                           61   \n",
       "1                        5.114                          101   \n",
       "2                        9.821                          485   \n",
       "3                        3.537                           40   \n",
       "4                        3.537                           40   \n",
       "5                        3.000                           15   \n",
       "\n",
       "   capital_run_length_total:  spam  \n",
       "0                        278     1  \n",
       "1                       1028     1  \n",
       "2                       2259     1  \n",
       "3                        191     1  \n",
       "4                        191     1  \n",
       "5                         54     1  \n",
       "\n",
       "[6 rows x 58 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import pylab as pl\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "pd.options.display.max_rows = 10\n",
    "\n",
    "# Import the spam dataset \n",
    "data= pd.read_csv(\"./spam_dataset.csv\")\n",
    "\n",
    "# print the first six rows\n",
    "data[0:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.  \n",
    "Read through the documentation of the original dataset \n",
    "\n",
    "The dependent variable is \"spam\" where one indicates that an email is spam and zero otherwise.  Which three variables in the dataset do you think will be important predictors in a model of spam?  Why?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think `word_freq_order:`,`char_freq_$:` and `capital_run_length_total:` would be important predictors in a model of spam. Because commercial marketing emails usually promote their products with the information of price (using $),  phrases like \"order now!\", and using capitialized phrases to catch attention."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.  \n",
    "Visualize the univariate distribution of each of the variables in the previous question. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/ml/lib/python3.7/site-packages/scipy/stats/stats.py:1713: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a1e1a94a8>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(data['word_freq_order:'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/ml/lib/python3.7/site-packages/scipy/stats/stats.py:1713: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a1e535a20>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(data['char_freq_$:'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/ml/lib/python3.7/site-packages/scipy/stats/stats.py:1713: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a1e638128>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAELCAYAAADHksFtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzt3XucldV97/HPd2aY4SbITYKAgkoSsUkxTlCTNDVJrZemITnVE0xeOaS1sRftSU7bNNi8jrX2eBpNGvtKYy7maDUeDRhiI7Ua6+0YcxEZjBcQiSOgjAJy8wbIMLN/549nDWw2e57ZM7NnNjjf9+s1r3n2etaz9nrWXL77uey1FRGYmZl1p67WHTAzs0Obg8LMzHI5KMzMLJeDwszMcjkozMwsl4PCzMxyOSjMzCyXg8LMzHI5KMzMLFdDrTtQDRMnTowZM2bUuhtmZoeVFStWbI2IST3Ve0sExYwZM2hpaal1N8zMDiuSnq+knk89mZlZLgeFmZnlqigoJJ0taY2kVkkLy6xvkrQ4rV8maUbRuktT+RpJZ6Wy6ZIelLRa0ipJny+qf7mkFyU9nr7O7f9umplZX/V4jUJSPXAtcCbQBiyXtDQini6qdiGwIyJOkDQfuAr4pKTZwHzgJOBo4D5Jbwc6gL+KiMckHQGskHRvUZvXRMTXqrWTZmbWd5UcUcwFWiNibUS0A4uAeSV15gE3peUlwEckKZUviog9EbEOaAXmRsTGiHgMICJeB1YDU/u/O2ZmVm2VBMVUYEPR4zYO/qe+r05EdACvAhMq2TadpjoZWFZUfImkJyXdIGlcBX00M7MBUklQqExZ6cfidVcnd1tJo4EfAV+IiNdS8beB44E5wEbgn8p2SrpIUoukli1btuTvgZmZ9VklQdEGTC96PA14qbs6khqAscD2vG0lDSMLiVsi4vauChGxOSI6I6IAfI/s1NdBIuK6iGiOiOZJk3p8v4iZmfVRJUGxHJglaaakRrKL00tL6iwFFqTl84AHIvsw7qXA/HRX1ExgFvBoun5xPbA6Ir5e3JCkKUUPPwGs7O1OmZlZ9fR411NEdEi6BLgHqAduiIhVkq4AWiJiKdk//ZsltZIdScxP266SdBvwNNmdThdHRKekDwCfAZ6S9Hh6qr+NiLuAqyXNITtFtR74kyrub7duXfZC2fJPnXrMYDy9mdkhS9kL/8Nbc3Nz9HcKDweFmQ01klZERHNP9fzObDMzy+WgMDOzXA4KMzPL5aAwM7NcDgozM8vloDAzs1wOCjMzy+WgMDOzXA4KMzPL5aAwM7NcDgozM8vloDAzs1wOCjMzy+WgMDOzXA4KMzPL5aAwM7NcDgozM8vloDAzs1wOCjMzy+WgMDOzXA4KMzPL5aAwM7NcDgozM8vloDAzs1wOCjMzy+WgMDOzXA4KMzPL5aAwM7NcDgozM8vloDAzs1wOCjMzy+WgMDOzXA4KMzPLVVFQSDpb0hpJrZIWllnfJGlxWr9M0oyidZem8jWSzkpl0yU9KGm1pFWSPl9Uf7ykeyU9m76P6/9umplZX/UYFJLqgWuBc4DZwAWSZpdUuxDYEREnANcAV6VtZwPzgZOAs4FvpfY6gL+KiBOB04CLi9pcCNwfEbOA+9NjMzOrkUqOKOYCrRGxNiLagUXAvJI684Cb0vIS4COSlMoXRcSeiFgHtAJzI2JjRDwGEBGvA6uBqWXaugn4eN92zczMqqGSoJgKbCh63Mb+f+oH1YmIDuBVYEIl26bTVCcDy1LR5IjYmNraCBxVQR/NzGyAVBIUKlMWFdbJ3VbSaOBHwBci4rUK+rL/CaWLJLVIatmyZUtvNjUzs16oJCjagOlFj6cBL3VXR1IDMBbYnretpGFkIXFLRNxeVGezpCmpzhTg5XKdiojrIqI5IponTZpUwW6YmVlfVBIUy4FZkmZKaiS7OL20pM5SYEFaPg94ICIilc9Pd0XNBGYBj6brF9cDqyPi6zltLQDu6O1OmZlZ9TT0VCEiOiRdAtwD1AM3RMQqSVcALRGxlOyf/s2SWsmOJOanbVdJug14muxOp4sjolPSB4DPAE9Jejw91d9GxF3AV4DbJF0IvACcX80dNjOz3lH2wv/w1tzcHC0tLf1q49ZlL5Qt/9Spx/SrXTOzQ5WkFRHR3FM9vzPbzMxyOSjMzCyXg8LMzHI5KMzMLJeDwszMcjkozMwsl4PCzMxyOSjMzCyXg8LMzHI5KMzMLJeDwszMcjkozMwsl4PCzMxyOSjMzCyXg8LMzHI5KMzMLJeDwszMcjkozMwsl4PCzMxyOSjMzCyXg8LMzHI5KMzMLJeDwszMcjkozMwsl4PCzMxyOSjMzCyXg8LMzHI5KMzMLJeDwszMcjkozMwsl4PCzMxyOSjMzCyXg8LMzHJVFBSSzpa0RlKrpIVl1jdJWpzWL5M0o2jdpal8jaSzispvkPSypJUlbV0u6UVJj6evc/u+e2Zm1l89BoWkeuBa4BxgNnCBpNkl1S4EdkTECcA1wFVp29nAfOAk4GzgW6k9gBtTWTnXRMSc9HVX73bJzMyqqZIjirlAa0SsjYh2YBEwr6TOPOCmtLwE+IgkpfJFEbEnItYBrak9IuKnwPYq7IOZmQ2gSoJiKrCh6HFbKitbJyI6gFeBCRVuW84lkp5Mp6fGVVDfzMwGSCVBoTJlUWGdSrYt9W3geGAOsBH4p7Kdki6S1CKpZcuWLT00aWZmfVVJULQB04seTwNe6q6OpAZgLNlppUq2PUBEbI6IzogoAN8jnaoqU++6iGiOiOZJkyZVsBtmZtYXlQTFcmCWpJmSGskuTi8tqbMUWJCWzwMeiIhI5fPTXVEzgVnAo3lPJmlK0cNPACu7q2tmZgOvoacKEdEh6RLgHqAeuCEiVkm6AmiJiKXA9cDNklrJjiTmp21XSboNeBroAC6OiE4AST8AzgAmSmoD/i4irgeuljSH7BTVeuBPqrnDZmbWO8pe+B/empubo6WlpV9t3LrshbLlnzr1mH61a2Z2qJK0IiKae6rnd2abmVkuB4WZmeVyUJiZWS4HhZmZ5XJQmJlZLgeFmZnlclCYmVkuB4WZmeVyUJiZWS4HhZmZ5XJQmJlZLgeFmZnlclCYmVkuB4WZmeVyUJiZWS4HhZmZ5XJQmJlZLgeFmZnlclCYmVkuB4WZmeVyUJiZWS4HhZmZ5XJQmJlZLgeFmZnlclCYmVkuB4WZmeVyUJiZWS4HhZmZ5XJQmJlZLgeFmZnlclCYmVkuB4WZmeVyUJiZWa6KgkLS2ZLWSGqVtLDM+iZJi9P6ZZJmFK27NJWvkXRWUfkNkl6WtLKkrfGS7pX0bPo+ru+7Z2Zm/dVjUEiqB64FzgFmAxdIml1S7UJgR0ScAFwDXJW2nQ3MB04Czga+ldoDuDGVlVoI3B8Rs4D702MzM6uRSo4o5gKtEbE2ItqBRcC8kjrzgJvS8hLgI5KUyhdFxJ6IWAe0pvaIiJ8C28s8X3FbNwEf78X+mJlZlVUSFFOBDUWP21JZ2ToR0QG8CkyocNtSkyNiY2prI3BUBX00M7MBUklQqExZVFinkm37RNJFkloktWzZsqUaTZqZWRmVBEUbML3o8TTgpe7qSGoAxpKdVqpk21KbJU1JbU0BXi5XKSKui4jmiGieNGlSBbthZmZ9UUlQLAdmSZopqZHs4vTSkjpLgQVp+TzggYiIVD4/3RU1E5gFPNrD8xW3tQC4o4I+mpnZAOkxKNI1h0uAe4DVwG0RsUrSFZI+lqpdD0yQ1Ar8JelOpYhYBdwGPA38BLg4IjoBJP0A+CXwDkltki5MbX0FOFPSs8CZ6bGZmdWIshf+h7fm5uZoaWnpVxu3LnuhbPmnTj2mX+2amR2qJK2IiOae6vmd2WZmlstBYWZmuRwUZmaWy0FhZma5HBRmZpbLQWFmZrkcFGZmlstBYWZmuRwUZmaWy0FhZma5HBRmZpbLQWFmZrkcFGZmlstBYWZmuRwUZmaWy0FhZma5HBRmZpbLQWFmZrkcFGZmlstBYWZmuRwU3fjZs1v4+r1r2Lmno9ZdMTOrKQdFiYjg7qc2ctfKTWx9o522Hbtr3SUzs5pyUJS4Z9VmHm7dyrETRgKwbeeeGvfIzKy2HBQlfr35dY6bNIp5c6YCsO2N9hr3yMysthwUJdo7CxzR1MDopgYAtr3hIwozG9ocFCX2dhRobKhjZGM9Arbv9BGFmQ1tDooS7Z0FGuvrqJMY2VjPVgeFmQ1xDooiEUF7R4FhDdmwjGpq8KknMxvyHBRFOgpBAI312bCMbmrwxWwzG/IcFEX2dhQAaCw6ovA1CjMb6hwURdo7U1DU7w+KrT71ZGZDnIOiSHs6oui6RjG6qZ7X3uzYV25mNhQ5KIqUO6IA2LHLp5/MbOiqKCgknS1pjaRWSQvLrG+StDitXyZpRtG6S1P5Gkln9dSmpBslrZP0ePqa079drNy+oOi6RtGYBYVPP5nZUNbQUwVJ9cC1wJlAG7Bc0tKIeLqo2oXAjog4QdJ84Crgk5JmA/OBk4CjgfskvT1tk9fmFyNiSRX2r1f2XcwuuusJPI2HmQ1tlRxRzAVaI2JtRLQDi4B5JXXmATel5SXARyQplS+KiD0RsQ5oTe1V0uaga+8MoPgaRQoKTwxoZkNYJUExFdhQ9LgtlZWtExEdwKvAhJxte2rzSklPSrpGUlMFfayK9o7y1yh8RGFmQ1klQaEyZVFhnd6WA1wKvBN4LzAe+FLZTkkXSWqR1LJly5ZyVXqt9BrF8GF1DKsX2/xeCjMbwioJijZgetHjacBL3dWR1ACMBbbnbNttmxGxMTJ7gH8lO011kIi4LiKaI6J50qRJFexGz0qvUUhi/KhGT+NhZkNaJUGxHJglaaakRrKL00tL6iwFFqTl84AHIiJS+fx0V9RMYBbwaF6bkqak7wI+Dqzszw72RtcRRUP9/gOeCaOa/O5sMxvSerzrKSI6JF0C3APUAzdExCpJVwAtEbEUuB64WVIr2ZHE/LTtKkm3AU8DHcDFEdEJUK7N9JS3SJpEdnrqceBPq7e7+do7CgyrF3UqCorRjWz1NQozG8J6DAqAiLgLuKuk7LKi5TeB87vZ9krgykraTOUfrqRPA2FvmmK82IRRjazftrNGPTIzqz2/M7tI8RTjXSaMbvJdT2Y2pDkoirSXO6IY3ciu9k52t3fWqFdmZrXloCiyt7Ow79bYLhNGNQJ+052ZDV0OiiLZxezSoMje7+fTT2Y2VDkoinR36gnwLbJmNmQ5KIq0d8RBp54mjs6OKDyDrJkNVQ6KIuVujx2frlG8/LqDwsyGJgdFkXK3x45srOftk0ezZEWbP+nOzIYkB0WRctcoJLHwnHeybutObln2fI16ZmZWOxW9M3so6CwEnYWgseHAiW1vXfYCEcHxk0Zx9U/WUCjAiMZ6PnXqMTXqqZnZ4PIRRbK35POyi0ninN+Ywpt7O3lwzcuD3TUzs5pyUCRd1x9Kr1F0OfrIEbx72lgeXb+dzkLpx3GYmb11OSiS9pwjii4nThlDe0eBl17ZPVjdMjOrOQdFsu9jULs5ogCYOXEUAOu2ejZZMxs6HBRJ3jWKLkcMH8ak0U2s3frGYHXLzKzmHBRJJUcUADMnjeL5bbvo6PR7KsxsaHBQJF3XKEonBSw1c+Io9nQUWPXSa4PRLTOzmnNQJBUfUaTrFMvWbRvwPpmZHQocFEkldz0BjBk+jImjm3hk7fbB6JaZWc05KJK9FR5RQHZUsXyd309hZkODgyKp9BoFwHETR/H6ng5WvvjqQHfLzKzmHBRJe0dQXyfq69Rj3eOPGs2wevHvT7w0CD0zM6stB0VSbubY7oxuauDM2ZP50WNt7OnoHOCemZnVloMi2dtRqOj6RJdPvvcYduzay71Pbx7AXpmZ1Z6DImnvLFR0faLLB06YyNQjR7B4+YYB7JWZWe05KJK9nYWDPosiT32dOL95Gg8/u5UN23cNYM/MzGrLH1yUtHdUfo0Csg80aqyvQ8Dnvt9C87HjOXbCSD73weMGrpNmZjXgoEjaOwuMbKzv1TZHjmzk/SdM5JfPbeOZTa9TJ9iwYxeXfPgEjjpi+AD11MxscDkokvaOAmNHDOv1due+awpnzp7MS6/s5lcbXuHWZS/ww5Y2/vb3TuQzpx17UP1Nr77JiGH1jB3Z++cyM6sFX6NI9vbi9thSw+rrOHbCKD4+Zyr3/eVvM3fmeP7nj1dy2R0rD5hl9o7HX+SMrz3IH39/ORF+V7eZHR58RJG09/L22O784rltnDl7MoVC8P1fPs89qzYxc+IoZkwYxaLlG5g8ponl63fwyNrtnH78hCr03MxsYA35I4pCmq+pN2+460mdxDnvmsL5p0xj+LB6HnvhFRYt38CC04/l/r86g0lHNHHtg61VeS4zs4E2pI8ovvvQczz06y3cfOGp7O0MhlXhiKLYyceM4+RjxlGIYM/eAiMa61n6+Es0HzuOu1du4qq7n+FL57yzqs9pZlZtFf1nlHS2pDWSWiUtLLO+SdLitH6ZpBlF6y5N5WskndVTm5JmpjaeTW029m8XuzduZCO/eG4btyx7Huh5ivG+qpMYUXRH1dyZ4xkxrJ77Vm/miQ2v8Py2nfuObMzMDjU9HlFIqgeuBc4E2oDlkpZGxNNF1S4EdkTECZLmA1cBn5Q0G5gPnAQcDdwn6e1pm+7avAq4JiIWSfpOavvb1djZUuedMo3FLRu46u5nAKp+RNGdpoZ6fmvWRP7z6c3Mu/bnQDYj7YL3zeAPTpnG6Kb9P5bd7Z3s2NVOZyHoLAQdhaCjUOCVXXvZvrOdo45o4pRjxyHlv1mwo7PAHY+/xIYduzh15gRmTxnD8vXbefjZLZww+QgueO90GgYoKM2sen6yciPrt+3iwg/M7NVsEv2hnu6+kXQ6cHlEnJUeXwoQEf9YVOeeVOeXkhqATcAkYGFx3a56abOD2gS+AmwB3hYRHaXP3Z3m5uZoaWmpeKeLrd74Gh/9l5/RWQj+4D3TOOXYcX1qp7cigrYdu9m5p4NX39zLY8/vYMOO3dTXiWPGj+R3Z0/mibZXWPH8DvZ25v+M5s4Yz5+dcTwTRzfR3lmgqaGOI0cOo7G+js2v7WHN5tf59v9r5bktOw/atrG+jvbOArOnjOGiDx5H245dPLdlJycdPYaPvvto3jZ2OBHB3s6oysV+6789HZ1s2L6LPR0Fjps4+oCjVRt8EXHAC7WOzgIdhWD4sPp963fs2kudYOyIYUhi554O1m/byZjhw5h65AgCeGbTa6zZ9DrHTRrNSUePYfNrb3L7Yy+yeuNr/M6JkznjHZP42n+u4QePZtMGzZl+JP9ywclMHz+yz32XtCIimnuqV8k1iqlA8YRGbcCp3dVJ/+BfBSak8kdKtp2alsu1OQF4JSI6ytQfECdOGcNn3zeD63+2blD/EUo64Ad86swJbNi+i5Uvvkrrlje47qdrmTxmOKcdN4GJo5qoqxN1In0XI4bVM6qpnvXbdvHQmpf5wxuX5z7fpCOa+PSpx3DcxNGs27qTTa/t5pjxo5gxYSSrN73OXU9t5AuLHwfgiKYG/u1XL3Llf6xmdFMDu/Z20lkImhrqGDeykSDYuaeTPR2d1NeJhro6GupFQ1qurxMN9ZVNh1LJXcJBZaflKmqrimf4Kr3FudKnrKS5zgi2vbGH4jOVbxszvOzvbrlx6+45ejMuFby4LHmcfQEI7SsDKEQQQfrKelxI7QshZaduAerq9pcVIigUDtymkNro+n2E7G7GzkLQUC8aG+ooFLKgzX6f6xnWIPZ2BG+mWaCHp7Ld7QV2t3dQXydGNjZQXyfe2NPB7vZOmobVMbqpgUIEr+7ey5t7C4xuamDM8Oxv5dXde4mAUY31jBkxjO0729mTPhgt+7ttYOsbe/aNT1NDHQ11Ymd75wFlXdtMHN3E3Ss37Vv3Z2ccz4lTxvDl25/i3G88zHc/cwrvO35ipT++PqkkKMr9xZf+pnRXp7vycv+R8+of3CnpIuCi9PANSWvK1euFiV+Brf1so6rWA8tgIlXo1/NA3465ulWVfg2AIdev5/u3+ZAbr34a9H6V/nwXXnXg4/f/PdD3fh38ruAyKgmKNmB60eNpQOkn9nTVaUunnsYC23vYtlz5VuBISQ3pqKLccwEQEdcB11XQ/4pIaqnkEGywuV+94371jvvVO0O1X5Wca1kOzEp3IzWSXZxeWlJnKbAgLZ8HPBDZ8elSYH66K2omMAt4tLs20zYPpjZIbd7R990zM7P+6vGIIl1zuAS4B6gHboiIVZKuAFoiYilwPXCzpFayI4n5adtVkm4DngY6gIsjohOgXJvpKb8ELJL0v4BfpbbNzKxGKnrDXUTcBdxVUnZZ0fKbwPndbHslcGUlbabytcDcSvpVZVU7jVVl7lfvuF+94371zpDsV4+3x5qZ2dDmG+PNzCyXg4Kepyip8nNNl/SgpNWSVkn6fCofL+neNHXJvZLGpXJJ+kbq25OS3lPU1oJU/1lJC7p7zl72r17SryTdmR6XnVKlL9O29KNPR0paIumZNG6nHwrjJel/pJ/hSkk/kDS8FuMl6QZJL0taWVRWtfGRdIqkp9I235B6mAYgv19fTT/HJyX9m6QjexqH7v4+uxvrvvSraN1fSwpJEw+F8Urlf5H2f5Wkqwd7vID0hpUh/EV2Mf054DigEXgCmD2AzzcFeE9aPgL4NTAbuBpYmMoXAlel5XOBu8neY3IasCyVjwfWpu/j0vK4KvTvL4FbgTvT49uA+Wn5O8CfpeU/B76TlucDi9Py7DSGTcDMNLb1/ezTTcAfp+VG4MhajxfZG0HXASOKxumztRgv4IPAe4CVRWVVGx+yOxVPT9vcDZzTj379LtCQlq8q6lfZcSDn77O7se5Lv1L5dLIbbJ4HJh4i4/Uh4D6gKT0+arDHKyIcFOkHek/R40uBSwfx+e8gm/NqDTAllU0B1qTl7wIXFNVfk9ZfAHy3qPyAen3syzTgfuDDwJ3pF31r0R/2vrFKf1Cnp+WGVE+l41dcr499GkP2D1kl5TUdL/bPRjA+7f+dwFm1Gi9gRsk/mKqMT1r3TFH5AfV626+SdZ8AbknLZceBbv4+8343+9ovYAnwm2Tvde0KipqOF9k/998pU29Qx8unnspPUTKg04Z0SacfTgaWAZMjYiNA+n5UD/0biH7/M/A3QNfH8uVNqXLAtC1A8bQt1ezXcWTzf/2rslNi/0fSKGo8XhHxIvA14AVgI9n+r6D249WlWuMzNS1Xu38Af0T2irsv/arqdD+SPga8GBFPlKyq9Xi9HfitdMroIUnv7WO/+jVeDopeTBtS1SeVRgM/Ar4QEa/lVS1T1qvpTirsz0eBlyNiRQXPPWj9Inv1/R7g2xFxMrCTNNlkNwZrvMYB88gO+48GRgHn5DzHYI1XT3rbjwHpn6Qvk7236pZa90vSSODLwGXlVteqX0kD2amt04AvArelax6D2i8HRWVTlFSVpGFkIXFLRNyeijdLmpLWTwFe7qF/1e73+4GPSVoPLCI7/fTPpClVyjzHvudX5dO29EUb0BYRy9LjJWTBUevx+h1gXURsiYi9wO3A+6j9eHWp1vi0peWq9S9d+P0o8OlI50H60K990/1UoV/HkwX+E+n3fxrwmKS39aFf1R6vNuD2yDxKdrQ/sQ/96t949fZc6Fvtiyyx15L9onRd/DlpAJ9PwPeBfy4p/yoHXny8Oi3/HgdeTHs0lY8nO3c/Ln2tA8ZXqY9nsP9i9g858ALYn6fliznw4uxtafkkDrzItpb+X8x+GHhHWr48jVVNx4tstuNVwMj0XDcBf1Gr8eLgc9tVGx+yKXdOY//F2XP70a+zyWZqmFRSr+w4kPP32d1Y96VfJevWs/8aRa3H60+BK9Ly28lOK2nQx6s/f8BvlS+yOxt+TXa3wJcH+Lk+QHbI9yTwePo6l+wc4v3As+l71y+dyD7k6TngKaC5qK0/AlrT1x9WsY9nsD8ojiO7i6M1/aJ13X0xPD1uTeuPK9r+y6m/a6jwjo8e+jOHbPLbJ4Efpz/Mmo8X8PfAM8BK4Ob0Rzvo4wX8gOw6yV6yV5QXVnN8gOa0j88B36TkxoJe9quV7J9d1+/+d3oaB7r5++xurPvSr5L169kfFLUer0bg/6b2HgM+PNjjFRF+Z7aZmeXzNQozM8vloDAzs1wOCjMzy+WgMDOzXA4KMzPL5aAwM7NcDgo7rEg6WtKStDxH0rkVbHOG0rTpg0nS5ZL+egDa/UKadqLr8Ru92PbjkmZXUO+zko6uoN6Nks7rqZ4d3hwUdliJiJciousf0xyyNxdVTdEUB4eyL5C9I7wvPk42RXVPPks2h5WZg8IGl6T/lj4A5glJN0v6/TQz5q8k3Sdpcqp3eVr/QPqglc+l8hnKPiioEbgC+KSkxyV9UtJcSb9Ibf1C0jsq7NPlkq6T9J/A99Or6W8Wrb9T0hlp+Q1JV6b+P9LV3wqe43hJP5G0QtLDkt6Zym9MH27zC0lru16dS6qT9K30YTV3SrpL0nmS/jvZP/AHJT1Y1H6PfZL0PuBjwFfTmB2fjsoe0f4PEhqX+tAM3JLqjZB0maTlaeyvSxPT2RDhoLBBI+kksmkHPhwRvwl8HvgZcFpkM8MuIpvmvMu7yebaOR24rPhUSES0k832uTgi5kTEYrLpND6Y2roM+N+96N4pwLyI+FQP9UYBj6T+/xT4XIXtXwf8RUScAvw18K2idVPIpnb5KPCVVPZfyOb9eRfwx2RjQER8g2wytw9FxId606eI+AWwFPhiGrPnyOYd+1JEvJtsioq/i4glZFOmfDrV2w18MyLeGxG/AYxIfT2ApCvSdN32FnM4HGbbW8eHgSURsRUgIrZLehewOM1w2kg2uVqXO9I/qd3p1fNcsvmBujMWuEnSLLL5tIb1om9L03P1pJ3sQ4og+/yJM3vaIE0p/z7gh0UvxJuKqvw4IgrA00VHAx8AfpjKNxUfPVSjT6lfY4EjI+KhVHQT2RxA5XxI0t+QnfIaTzYh4r8XV4iIctN021uAjyhsMImD58D/F7JXq+8C/oRs8rwupXV7mpjsH4AH06ve3y9pqyc7i5Y7OPBvo7jjyIQgAAABt0lEQVSdvbF/grROKnuxVUf2oTFzir5OLFq/p2hZJd8r0Zc+VUzScLIjoPPSz+l79G5s7TDnoLDBdD/wXyVNAJA0nuwo4MW0fkFJ/XmShqf6Z5BN31zsdbLPHe9S3NZn+9HP9cCcdJ1gOtmRTJ9F9sFU6ySdD6DMb/aw2c+AP0h9mEy2/11K97s39m0bEa8COyT9Vlr3GeCh0nrsD4Wt6ejIdzkNMQ4KGzQRsQq4EnhI0hPA18k+X+KHkh4m+3CVYo8C/wE8AvxDRJR+0MqDwOyui9nA1cA/Svo52dz8ffVzslNgT5F93Olj/Wiry6eBC9N+ryL7dLw8PyKbanol2ecxLyP7+FTIrnfc3cPpqO4sAr6YLvgfTxbOX5X0JNldZFekejcC35H0ONkRz/fIxuPHHBzYgK9RvJV5mnE7JEm6HHgjIr5W677UiqTREfFGOqJ6FHh/RGyqdb9s6PHFbLND152SjiS7yP8PDgmrFR9R2JAh6Q/Jbskt9vOIuLif7X4ZOL+k+IcRcWV/2u2PQ7FPdvhyUJiZWS5fzDYzs1wOCjMzy+WgMDOzXA4KMzPL5aAwM7Nc/x8nee4YrwkukQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(data['capital_run_length_total:'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. \n",
    "Drawing from the *full spam dataset*, name each of the supervised learning models that we have learned thus far that are used to predict dependent variables like \"spam\".  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['spam']\n",
    "X = data.loc[:, data.columns != 'spam']\n",
    "\n",
    "## Scaling data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "Xss = StandardScaler()\n",
    "X_s = Xss.fit_transform(X)\n",
    "X_s = pd.DataFrame(X_s,columns=X.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) KNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# initialize model\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_s, y)\n",
    "\n",
    "# predictions\n",
    "knn_pred = knn.predict(X_s) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Ham</th>\n",
       "      <th>Predicted Spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>True Ham</th>\n",
       "      <td>2655</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True Spam</th>\n",
       "      <td>159</td>\n",
       "      <td>1654</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Predicted Ham  Predicted Spam\n",
       "True Ham            2655             133\n",
       "True Spam            159            1654"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.95      0.95      2788\n",
      "          1       0.93      0.91      0.92      1813\n",
      "\n",
      "avg / total       0.94      0.94      0.94      4601\n",
      "\n",
      "overall accuracy: 0.93654\n"
     ]
    }
   ],
   "source": [
    "# classification_report matrix\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "display(pd.DataFrame(\n",
    "    confusion_matrix(y, knn_pred),\n",
    "    columns=['Predicted Ham', 'Predicted Spam'],\n",
    "    index=['True Ham', 'True Spam']\n",
    "))\n",
    "\n",
    "print(classification_report(y, knn_pred))\n",
    "\n",
    "# percent of correct prediction\n",
    "print(\"overall accuracy: {:.5f}\".format(knn.score(X_s, y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) (Penalized) Logistic regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# initialize model\n",
    "lr = LogisticRegression(C=1e9)\n",
    "lr.fit(X_s,y)\n",
    "\n",
    "# predictions\n",
    "lr_pred = lr.predict(X_s) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Ham</th>\n",
       "      <th>Predicted Spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>True Ham</th>\n",
       "      <td>2667</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True Spam</th>\n",
       "      <td>195</td>\n",
       "      <td>1618</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Predicted Ham  Predicted Spam\n",
       "True Ham            2667             121\n",
       "True Spam            195            1618"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.96      0.94      2788\n",
      "          1       0.93      0.89      0.91      1813\n",
      "\n",
      "avg / total       0.93      0.93      0.93      4601\n",
      "\n",
      "overall accuracy: 0.93132\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "display(pd.DataFrame(\n",
    "    confusion_matrix(y, lr_pred),\n",
    "    columns=['Predicted Ham', 'Predicted Spam'],\n",
    "    index=['True Ham', 'True Spam']\n",
    "))\n",
    "\n",
    "# classification_report matrix  \n",
    "print(classification_report(y, lr_pred))  \n",
    "\n",
    "\n",
    "# percent of correct prediction\n",
    "print(\"overall accuracy: {:.5f}\".format(lr.score(X_s, y)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(Penalized)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialize model\n",
    "plr = LogisticRegression(C=1)\n",
    "plr.fit(X_s, y)\n",
    "\n",
    "# predictions\n",
    "plr_pred = plr.predict(X_s) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Ham</th>\n",
       "      <th>Predicted Spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>True Ham</th>\n",
       "      <td>2666</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True Spam</th>\n",
       "      <td>199</td>\n",
       "      <td>1614</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Predicted Ham  Predicted Spam\n",
       "True Ham            2666             122\n",
       "True Spam            199            1614"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.96      0.94      2788\n",
      "          1       0.93      0.89      0.91      1813\n",
      "\n",
      "avg / total       0.93      0.93      0.93      4601\n",
      "\n",
      "overall accuracy: 0.93023\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "display(pd.DataFrame(\n",
    "    confusion_matrix(y, plr_pred),\n",
    "    columns=['Predicted Ham', 'Predicted Spam'],\n",
    "    index=['True Ham', 'True Spam']\n",
    "))\n",
    "\n",
    "# classification_report matrix \n",
    "print(classification_report(y, plr_pred))  \n",
    "\n",
    "\n",
    "# percent of correct prediction\n",
    "print(\"overall accuracy: {:.5f}\".format(plr.score(X_s, y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# simple SVM: linear kernel\n",
    "svm = SVC(kernel='linear')  \n",
    "svm.fit(X_s, y) \n",
    "\n",
    "svm_pred = svm.predict(X_s)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Ham</th>\n",
       "      <th>Predicted Spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>True Ham</th>\n",
       "      <td>2663</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True Spam</th>\n",
       "      <td>185</td>\n",
       "      <td>1628</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Predicted Ham  Predicted Spam\n",
       "True Ham            2663             125\n",
       "True Spam            185            1628"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.96      0.94      2788\n",
      "          1       0.93      0.90      0.91      1813\n",
      "\n",
      "avg / total       0.93      0.93      0.93      4601\n",
      "\n",
      "overall accuracy: 0.93262\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "display(pd.DataFrame(\n",
    "    confusion_matrix(y, svm_pred),\n",
    "    columns=['Predicted Ham', 'Predicted Spam'],\n",
    "    index=['True Ham', 'True Spam']\n",
    "))\n",
    "  \n",
    "print(classification_report(y, svm_pred))  \n",
    "\n",
    "print(\"overall accuracy: {:.5f}\".format(svm.score(X_s, y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Gaussian Kernel\n",
    "gsvm = SVC(kernel='rbf')  \n",
    "gsvm.fit(X_s, y)  \n",
    "\n",
    "gsvm_pred = gsvm.predict(X_s)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Ham</th>\n",
       "      <th>Predicted Spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>True Ham</th>\n",
       "      <td>2697</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True Spam</th>\n",
       "      <td>151</td>\n",
       "      <td>1662</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Predicted Ham  Predicted Spam\n",
       "True Ham            2697              91\n",
       "True Spam            151            1662"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.97      0.96      2788\n",
      "          1       0.95      0.92      0.93      1813\n",
      "\n",
      "avg / total       0.95      0.95      0.95      4601\n",
      "\n",
      "overall accuracy: 0.94740\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "display(pd.DataFrame(\n",
    "    confusion_matrix(y, gsvm_pred),\n",
    "    columns=['Predicted Ham', 'Predicted Spam'],\n",
    "    index=['True Ham', 'True Spam']\n",
    "))\n",
    "  \n",
    "print(classification_report(y, gsvm_pred))  \n",
    "\n",
    "print(\"overall accuracy: {:.5f}\".format(gsvm.score(X_s, y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d) Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree = DecisionTreeClassifier()\n",
    "tree.fit(X_s,y)\n",
    "\n",
    "tree_pred = tree.predict(X_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Ham</th>\n",
       "      <th>Predicted Spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>True Ham</th>\n",
       "      <td>2788</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True Spam</th>\n",
       "      <td>3</td>\n",
       "      <td>1810</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Predicted Ham  Predicted Spam\n",
       "True Ham            2788               0\n",
       "True Spam              3            1810"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      2788\n",
      "          1       1.00      1.00      1.00      1813\n",
      "\n",
      "avg / total       1.00      1.00      1.00      4601\n",
      "\n",
      "overall accuracy: 0.99935\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "display(pd.DataFrame(\n",
    "    confusion_matrix(y, tree_pred),\n",
    "    columns=['Predicted Ham', 'Predicted Spam'],\n",
    "    index=['True Ham', 'True Spam']\n",
    "))\n",
    "\n",
    "print(classification_report(y, tree_pred))  \n",
    "\n",
    "print(\"overall accuracy: {:.5f}\".format(tree.score(X_s, y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e) Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/ml/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "rf.fit(X_s,y)\n",
    "\n",
    "rf_pred = rf.predict(X_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Ham</th>\n",
       "      <th>Predicted Spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>True Ham</th>\n",
       "      <td>2785</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True Spam</th>\n",
       "      <td>27</td>\n",
       "      <td>1786</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Predicted Ham  Predicted Spam\n",
       "True Ham            2785               3\n",
       "True Spam             27            1786"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99      2788\n",
      "          1       1.00      0.99      0.99      1813\n",
      "\n",
      "avg / total       0.99      0.99      0.99      4601\n",
      "\n",
      "overall accuracy: 0.99348\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "display(pd.DataFrame(\n",
    "    confusion_matrix(y, rf_pred),\n",
    "    columns=['Predicted Ham', 'Predicted Spam'],\n",
    "    index=['True Ham', 'True Spam']\n",
    "))\n",
    "\n",
    "print(classification_report(y, rf_pred))  \n",
    "\n",
    "print(\"overall accuracy: {:.5f}\".format(rf.score(X_s, y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### f) Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "tree = DecisionTreeClassifier() \n",
    "bag = BaggingClassifier(tree)\n",
    "\n",
    "bag.fit(X_s,y)\n",
    "\n",
    "bag_pred = bag.predict(X_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Ham</th>\n",
       "      <th>Predicted Spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>True Ham</th>\n",
       "      <td>2786</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True Spam</th>\n",
       "      <td>15</td>\n",
       "      <td>1798</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Predicted Ham  Predicted Spam\n",
       "True Ham            2786               2\n",
       "True Spam             15            1798"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      1.00      2788\n",
      "          1       1.00      0.99      1.00      1813\n",
      "\n",
      "avg / total       1.00      1.00      1.00      4601\n",
      "\n",
      "overall accuracy: 0.99631\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "display(pd.DataFrame(\n",
    "    confusion_matrix(y, bag_pred),\n",
    "    columns=['Predicted Ham', 'Predicted Spam'],\n",
    "    index=['True Ham', 'True Spam']\n",
    "))\n",
    "\n",
    "print(classification_report(y, bag_pred))  \n",
    "\n",
    "print(\"overall accuracy: {:.5f}\".format(bag.score(X_s, y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 5. \n",
    "Describe the importance of training and test data.  Why do we separate data into these subsets?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because out goal is to build a model to make accurate predictions on new data with the same features as the data we have seen. Without the partition of training and test subsets, we tend to build models overfit the current dataset, but hard to generalize to new data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The evaluation of a model is based on how well it perferm on new data. Without new data, we split current data into two subsets: training and test, and use to test dataset to evaluate our model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. \n",
    "What is k-fold cross validation and what do we use it for?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-fold cross validation is to split the dataset into k parts of equal size, called folds; and a series of models are trained by using one fold as test data. And then we gain k accuracy values, and take the mean of those values. Compared to a single split into test and training, K-fold cross validation gives us more stable evaluation of generalization perfermance since each example will be in the training dataset once, the model need to generalize well to all the samples in a dataset to get a high mean of cross-validation scores. And k-fold cross validation help use to make use of our data more effectively since we gain more information than a single split."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. \n",
    "How is k-fold cross validation different from stratified k-fold cross validation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-fold cross validation only split the data into k folds. Stratified K-fold cross validation split the data to ensure the proportions between classes are the same in each fold, which provide more reliable estimates of generalization performance for evaluating classfication models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. \n",
    "Choose one model from question four. -- **KNN**\n",
    "\n",
    "Split the data into training and test subsets.  Build a model with the three variables in the dataset that you think will be good predictors of \"spam\".  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = data['spam']\n",
    "X = data[['word_freq_order:','char_freq_$:', 'capital_run_length_total:']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3450 entries, 118 to 2732\n",
      "Data columns (total 3 columns):\n",
      "word_freq_order:             3450 non-null float64\n",
      "char_freq_$:                 3450 non-null float64\n",
      "capital_run_length_total:    3450 non-null int64\n",
      "dtypes: float64(2), int64(1)\n",
      "memory usage: 107.8 KB\n"
     ]
    }
   ],
   "source": [
    "# Training test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "## Scaling data\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_s = scaler.transform(X_train)\n",
    "\n",
    "scaler.fit(X_test)\n",
    "X_test_s = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe why you chose any particular parameters for your model (e.g.- if you used KNN how did you decide to choose a specific value for k). \n",
    "\n",
    "I use `GridSeachCV` to find that k=17 has the best cross validation socre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best mean cross-validation score: 0.78319\n",
      "best parameters: {'n_neighbors': 17}\n"
     ]
    }
   ],
   "source": [
    "## GridSearchCV to find the best tuning parameter\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "param_grid = {'n_neighbors': np.arange(1, 21, 2)} \n",
    "\n",
    "grid = GridSearchCV(KNeighborsClassifier(), param_grid=param_grid, cv=10)\n",
    "\n",
    "grid.fit(X_train_s, y_train)\n",
    "\n",
    "print(\"best mean cross-validation score: {:.5f}\".format(grid.best_score_))\n",
    "print(\"best parameters: {}\".format(grid.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the model and evaluate prediction error in two ways. A) On test data directly and B) using k-fold cross-validation.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set score: 0.77585\n"
     ]
    }
   ],
   "source": [
    "# A) on the test data\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=17)\n",
    "knn.fit(X_train_s, y_train)\n",
    "\n",
    "print(\"Test set score: {:.5f}\".format(knn.score(X_test_s, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average cross-validation score: 0.78493\n"
     ]
    }
   ],
   "source": [
    "# B) using k-fold cross-validation.\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "k_fold = KFold(n_splits=10)\n",
    "\n",
    "print(\"Average cross-validation score: {:.5f}\".format(np.mean(cross_val_score(KNeighborsClassifier(n_neighbors=17), \n",
    "                                                                              X_train_s, \n",
    "                                                                              y_train, \n",
    "                                                                              cv= k_fold))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. \n",
    "Choose a second model from question four.  -- **Penalized Logistic Regression**\n",
    "\n",
    "Using the same three variables in the dataset that you think will be good predictors of \"spam\".  Describe why you chose any particular parameters for your model (e.g.- if you used KNN how did you decide to choose a specific value for k).  \n",
    "\n",
    "I use `GridSeachCV` to find that c=100 has the best cross validation socre.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best mean cross-validation score: 0.77565\n",
      "best parameters: {'C': 100}\n"
     ]
    }
   ],
   "source": [
    "## GridSearchCV to find the best tuning parameter\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "para_lg = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000] }\n",
    "\n",
    "gs_lg = GridSearchCV(LogisticRegression(), param_grid=para_lg, cv=10)\n",
    "\n",
    "lggrid = gs_lg.fit(X_train_s, y_train)\n",
    "\n",
    "print(\"best mean cross-validation score: {:.5f}\".format(lggrid.best_score_))\n",
    "print(\"best parameters: {}\".format(lggrid.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set score: 0.77237\n"
     ]
    }
   ],
   "source": [
    "# A) on the test data\n",
    "\n",
    "logreg = LogisticRegression(C=100)\n",
    "\n",
    "logreg.fit(X_train_s, y_train)\n",
    "\n",
    "print(\"Test set score: {:.5f}\".format(logreg.score(X_test_s, y_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the model and evaluate prediction error in two ways. A) On test data directly and B) using k-fold cross-validation.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average cross-validation score: 0.77478\n"
     ]
    }
   ],
   "source": [
    "# B) using k-fold cross-validation.\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "k_fold = KFold(n_splits=10)\n",
    "\n",
    "print(\"Average cross-validation score: {:.5f}\".format(np.mean(cross_val_score(LogisticRegression(C=100), \n",
    "                                                                              X_train_s, \n",
    "                                                                              y_train, \n",
    "                                                                              cv= k_fold))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Did this model predict test data better than your previous models?**\n",
    "\n",
    "No"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. \n",
    "Choose a third model from question four.  -- **SVM**\n",
    "\n",
    "Using the same three variables in the dataset that you think will be good predictors of \"spam\".  Describe why you chose any particular parameters for your model (e.g.- if you used KNN how did you decide to choose a specific value for k). \n",
    "\n",
    "I use `GridSeachCV` to find that kernel = 'rbf'; C=10; gamma = 1 has the best cross validation socre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best mean cross-validation score: 0.80000\n",
      "best parameters: {'C': 10, 'gamma': 1, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm, grid_search\n",
    "\n",
    "Cs = [0.001, 0.01, 0.1, 1, 10]\n",
    "gammas = [0.001, 0.01, 0.1, 1]\n",
    "kernels = ['linear','rbf']\n",
    "         \n",
    "\n",
    "param_svm = {'C': Cs, 'gamma' : gammas, 'kernel': kernels}\n",
    "\n",
    "grid_svm = GridSearchCV(svm.SVC(), param_grid = param_svm, cv=10)\n",
    "\n",
    "svmgrid = grid_svm.fit(X_train_s, y_train)\n",
    "\n",
    "print(\"best mean cross-validation score: {:.5f}\".format(svmgrid.best_score_))\n",
    "\n",
    "print(\"best parameters: {}\".format(svmgrid.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the model and evaluate prediction error in two ways. A) On test data directly and B) using k-fold cross-validation.  Did this model predict test data better than your previous models?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set score: 0.79235\n"
     ]
    }
   ],
   "source": [
    "# A) on the test data\n",
    "\n",
    "bestsvm = svm.SVC(kernel='rbf', C = 10, gamma= 1)  \n",
    "\n",
    "bestsvm.fit(X_train_s, y_train)  \n",
    "\n",
    "print(\"Test set score: {:.5f}\".format(bestsvm.score(X_test_s, y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average cross-validation score: 0.80029\n"
     ]
    }
   ],
   "source": [
    "# B) using k-fold cross-validation.\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "k_fold = KFold(n_splits=10)\n",
    "\n",
    "print(\"Average cross-validation score: {:.5f}\".format(np.mean(cross_val_score(svm.SVC(kernel='rbf', C = 10, gamma= 1), \n",
    "                                                                              X_train_s, \n",
    "                                                                              y_train, \n",
    "                                                                              cv= k_fold))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Did this model predict test data better than your previous models?**\n",
    "\n",
    "-- Yes, both in terms of test data and k-fold cross validation show the improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. \n",
    "Choose a fourth model from question four.  --**Decision Tree**\n",
    "\n",
    "Using the same three variables in the dataset that you think will be good predictors of \"spam\".  Describe why you chose any particular parameters for your model (e.g.- if you used KNN how did you decide to choose a specific value for k). \n",
    "\n",
    "I use `GridSeachCV` to find that criterion = entropy; max_depth = 6; min_samples_leaf= 2 has the best cross validation socre.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best mean cross-validation score: 0.79855\n",
      "best parameters: {'criterion': 'entropy', 'max_depth': 6, 'min_samples_leaf': 2}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree = DecisionTreeClassifier()\n",
    "#Hyper Parameters Set\n",
    "params_tree = {'max_depth': np.arange(1, 21),\n",
    "          'criterion': ['gini','entropy'], \n",
    "          'min_samples_leaf':np.arange(1, 21)}\n",
    "         \n",
    "grid_tree = GridSearchCV(DecisionTreeClassifier(), param_grid = params_tree, cv=10)\n",
    "\n",
    "treegrid = grid_tree.fit(X_train_s, y_train)\n",
    "\n",
    "print(\"best mean cross-validation score: {:.5f}\".format(treegrid.best_score_))\n",
    "\n",
    "print(\"best parameters: {}\".format(treegrid.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the model and evaluate prediction error in two ways. A) On test data directly and B) using k-fold cross-validation.  Did this model predict test data better than your previous models?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set score: 0.79670\n"
     ]
    }
   ],
   "source": [
    "# A) on the test data\n",
    "\n",
    "bestress = DecisionTreeClassifier(criterion = 'entropy', max_depth = 6, min_samples_leaf= 2)\n",
    "\n",
    "bestress.fit(X_train_s, y_train)  \n",
    "\n",
    "print(\"Test set score: {:.5f}\".format(bestress.score(X_test_s, y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average cross-validation score: 0.79565\n"
     ]
    }
   ],
   "source": [
    "# B) using k-fold cross-validation.\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "k_fold = KFold(n_splits=10)\n",
    "\n",
    "print(\"Average cross-validation score: {:.5f}\".format(np.mean(cross_val_score(bestress, \n",
    "                                                                              X_train_s, \n",
    "                                                                              y_train, \n",
    "                                                                              cv= k_fold))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Did this model predict test data better than your previous models?**\n",
    "\n",
    "-- Compared to KNN and Penalized Logistic Regression , decision tree model improves the performance, but not as good as SVM. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. \n",
    "Now rerun your best model from questions 8 through 11, but this time add three new variables to the model that you think will increase prediction accuracy.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3450 entries, 118 to 2732\n",
      "Data columns (total 6 columns):\n",
      "word_freq_order:               3450 non-null float64\n",
      "char_freq_$:                   3450 non-null float64\n",
      "capital_run_length_total:      3450 non-null int64\n",
      "word_freq_free:                3450 non-null float64\n",
      "capital_run_length_average:    3450 non-null float64\n",
      "char_freq_!:                   3450 non-null float64\n",
      "dtypes: float64(5), int64(1)\n",
      "memory usage: 188.7 KB\n"
     ]
    }
   ],
   "source": [
    "y = data['spam']\n",
    "X_3 = data[['word_freq_order:','char_freq_$:', 'capital_run_length_total:',\n",
    "          'word_freq_free:', 'capital_run_length_average:', 'char_freq_!:']]\n",
    "\n",
    "# Training test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_3, X_test_3, y_train_3, y_test_3 = train_test_split(X_3, y, random_state=0)\n",
    "X_train_3.info()\n",
    "\n",
    "from sklearn import preprocessing\n",
    "## Scaling data\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(X_train_3)\n",
    "X_train_3s = scaler.transform(X_train_3)\n",
    "\n",
    "scaler.fit(X_test_3)\n",
    "X_test_3s = scaler.transform(X_test_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set score: 0.87142\n",
      "Average cross-validation score: 0.88290\n"
     ]
    }
   ],
   "source": [
    "bestsvm = svm.SVC(kernel='rbf', C = 10, gamma= 1)  \n",
    "\n",
    "bestsvm.fit(X_train_3s, y_train_3)  \n",
    "\n",
    "# A) on test data\n",
    "print(\"Test set score: {:.5f}\".format(bestsvm.score(X_test_3s, y_test_3)))\n",
    "\n",
    "# B) using k-fold cross-validation.\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "k_fold = KFold(n_splits=10)\n",
    "\n",
    "print(\"Average cross-validation score: {:.5f}\".format(np.mean(cross_val_score(bestsvm, \n",
    "                                                                              X_train_3s, \n",
    "                                                                              y_train_3, \n",
    "                                                                              cv= k_fold))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Did this model predict test data better than your previous models?**\n",
    "\n",
    "-- Yes, the model predict better with 3 more features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13. \n",
    "Rerun all your other models with this final set of six variables, evaluate prediction error, and choose a final model.  Why did you select this model among all of the models that you ran?  \n",
    "\n",
    "**-- With 3 more features, every model get improvement. The SVM model still has the best performance on test data and 10 fold validation score. So I select SVM model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set score: 0.85317\n",
      "Average cross-validation score: 0.87710\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "bestress = DecisionTreeClassifier(criterion = 'entropy', max_depth = 6, min_samples_leaf= 2)\n",
    "bestress.fit(X_train_3s, y_train_3)  \n",
    "\n",
    "# A) on test data\n",
    "print(\"Test set score: {:.5f}\".format(bestress.score(X_test_3s, y_test_3)))\n",
    "\n",
    "# B) using k-fold cross-validation.\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "k_fold = KFold(n_splits=10)\n",
    "\n",
    "print(\"Average cross-validation score: {:.5f}\".format(np.mean(cross_val_score(bestress, \n",
    "                                                                              X_train_3s, \n",
    "                                                                              y_train_3, \n",
    "                                                                              cv= k_fold))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set score: 0.84448\n",
      "Average cross-validation score: 0.83536\n"
     ]
    }
   ],
   "source": [
    "# Penalized Logistic Regression\n",
    "logreg = LogisticRegression(C=100)\n",
    "\n",
    "logreg.fit(X_train_3s, y_train_3)  \n",
    "\n",
    "# A) on test data\n",
    "print(\"Test set score: {:.5f}\".format(logreg.score(X_test_3s, y_test_3)))\n",
    "\n",
    "# B) using k-fold cross-validation.\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "k_fold = KFold(n_splits=10)\n",
    "\n",
    "print(\"Average cross-validation score: {:.5f}\".format(np.mean(cross_val_score(logreg, \n",
    "                                                                              X_train_3s, \n",
    "                                                                              y_train_3, \n",
    "                                                                              cv= k_fold))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set score: 0.85925\n",
      "Average cross-validation score: 0.86783\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=17)\n",
    "knn.fit(X_train_3s, y_train_3)  \n",
    "\n",
    "# A) on test data\n",
    "print(\"Test set score: {:.5f}\".format(knn.score(X_test_3s, y_test_3)))\n",
    "\n",
    "# B) using k-fold cross-validation.\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "k_fold = KFold(n_splits=10)\n",
    "\n",
    "print(\"Average cross-validation score: {:.5f}\".format(np.mean(cross_val_score(knn, \n",
    "                                                                              X_train_3s, \n",
    "                                                                              y_train_3, \n",
    "                                                                              cv= k_fold))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14. \n",
    "What variable that currently is not in your model, if included, would be likely to increase your final model's predictive power?\n",
    "\n",
    "**-- 'word_freq_receive:', 'word_freq_credit:', 'capital_run_length_longest:'**\n",
    "\n",
    "The svm imporved marginally after include this 3 variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y = data['spam']\n",
    "X_6 = data[['word_freq_order:','char_freq_$:', 'capital_run_length_total:',\n",
    "          'word_freq_free:', 'capital_run_length_average:', 'char_freq_!:',\n",
    "           'word_freq_receive:', 'word_freq_credit:', 'capital_run_length_longest:']]\n",
    "\n",
    "# Training test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_6, X_test_6, y_train_6, y_test_6 = train_test_split(X_6, y, random_state=0)\n",
    "\n",
    "from sklearn import preprocessing\n",
    "## Scaling data\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(X_train_6)\n",
    "X_train_6s = scaler.transform(X_train_6)\n",
    "\n",
    "scaler.fit(X_test_6)\n",
    "X_test_6s = scaler.transform(X_test_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set score: 0.86099\n",
      "Average cross-validation score: 0.88696\n"
     ]
    }
   ],
   "source": [
    "bestsvm = svm.SVC(kernel='rbf', C = 10, gamma= 1)  \n",
    "\n",
    "bestsvm.fit(X_train_6s, y_train_6)  \n",
    "\n",
    "# A) on test data\n",
    "print(\"Test set score: {:.5f}\".format(bestsvm.score(X_test_6s, y_test_6)))\n",
    "\n",
    "# B) using k-fold cross-validation.\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "k_fold = KFold(n_splits=10)\n",
    "\n",
    "print(\"Average cross-validation score: {:.5f}\".format(np.mean(cross_val_score(bestsvm, \n",
    "                                                                              X_train_6s, \n",
    "                                                                              y_train_6, \n",
    "                                                                              cv= k_fold))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15. \n",
    "Lastly, you have listed each of the models that we have learned to use to predict dependent variables like spam.  List each model we have focused on in class thus far that you could use to evaluate data with a continuous dependent variable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- KNN for regression\n",
    "- OLS regression\n",
    "- Ridge regression\n",
    "- Lasso regression\n",
    "- Decision Tree regression\n",
    "- Random Forest regression\n",
    "- Bagging regression\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml]",
   "language": "python",
   "name": "conda-env-ml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
